{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ON-UmcT_ZFqw"
   },
   "source": [
    "## Guide to tf.keras for TPUs on Colabs\n",
    "\n",
    "Here is a very quick implemention and walkthrough to show using TPUs with Keras in Colabs\n",
    "\n",
    "License: Apache 2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dPamRBokUZEq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten,Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "95qn1rJyHFz5",
    "outputId": "011699d7-09e9-43fc-d7b3-73137492b00a"
   },
   "outputs": [],
   "source": [
    "print(\"Running TensorFlow: %s\" % tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zq4l11_Dtx8b"
   },
   "source": [
    "## Check for TPU\n",
    "\n",
    "To Test if you have GPU set up, run the Cell below\n",
    "\n",
    "if no TPU is found click on Runtime (in the menu at the top) \n",
    "    - Choose \"Change Runtime Type\" and select TPU from the dropdown menu\n",
    "\n",
    "The TPU_ADDRESS variable will be passed into the distribution strategy in the code later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dwqHrONrZtng",
    "outputId": "bde64846-603c-43b6-9393-4f4e68f5c1e4"
   },
   "outputs": [],
   "source": [
    "# Check if a TPU address is returned, else change Runtime\n",
    "try:\n",
    "    device_name = os.environ['COLAB_TPU_ADDR']\n",
    "    TPU_ADDRESS = 'grpc://' + device_name\n",
    "    print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
    "\n",
    "except KeyError:\n",
    "    print('TPU not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6mOaxj3k30j"
   },
   "source": [
    "### Hello World in Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "181VT0eOUkL3"
   },
   "outputs": [],
   "source": [
    "# Notice the batch size used below, a multiple of 128\n",
    "batch_size = 1024  # 2048 or 4096 is also fine\n",
    "num_classes = 10\n",
    "epochs = 5   # Test fast, fail fast\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Input image dimensions - typical of (Fashion) MNIST\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "LHmvV1heVGDi",
    "outputId": "1d538dd0-c0ca-4272-8d7e-d1c82ecd3290"
   },
   "outputs": [],
   "source": [
    "# Image and label data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1tidRmu9VM4E"
   },
   "outputs": [],
   "source": [
    "# Reshaping to vectorize the input images\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "vfinmHzDX6SH",
    "outputId": "d3eedbc4-0bcc-43d7-f2c3-7f6f2cd035b9"
   },
   "outputs": [],
   "source": [
    "# Normalizing the input images \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HpOYyqEnX-G1"
   },
   "outputs": [],
   "source": [
    "# Convert class labels into a one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O_K39jsGzJL-"
   },
   "source": [
    "## Using tf.data\n",
    "\n",
    "Make sure you have drop_remainder = True as TPUs need to have a fixed shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "abbwQQfH0td3"
   },
   "outputs": [],
   "source": [
    "def train_input_fn(batch_size=1024):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.cache() # Loads the data into memory since its such a small dataset\n",
    "    dataset = dataset.shuffle(1000, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.repeat() \n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)  # TPUs need to have a fixed shape\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVu91avJzMAO"
   },
   "outputs": [],
   "source": [
    "def test_input_fn(batch_size=1024):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_test,y_test))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.shuffle(1000, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)  # TPUs need to have a fixed shape\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G_spUwX0VYGt"
   },
   "source": [
    "## The Convolutional NN Model\n",
    "\n",
    "Pass in an input shape and batch size as TPUs (and XLA) require fixed shapes \n",
    "\n",
    "Rest of the model definition is a typical Convolutional NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "qHzyhDMhVXHy",
    "outputId": "d720a06b-7bd9-4aea-d4cd-4ca1a03393fd"
   },
   "outputs": [],
   "source": [
    "Input_layer = tf.keras.Input(\n",
    "      name='input', shape=input_shape, batch_size=batch_size, dtype=tf.float32)\n",
    "x = Conv2D(32, kernel_size=(3, 3), activation='relu',name = 'Conv_01')(Input_layer)\n",
    "x = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool_01')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu',name = 'Conv_02')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2),name = 'MaxPool_02')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu',name = 'Conv_03')(x)\n",
    "x = Flatten(name = 'Flatten_01')(x)\n",
    "x = Dense(64, activation='relu',name = 'Dense_01')(x)\n",
    "x = Dropout(0.5,name = 'Dropout_02')(x)\n",
    "Output_layer = Dense(num_classes, activation='softmax',name = 'Dense_02')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xj-jMmGnuKX0"
   },
   "outputs": [],
   "source": [
    "# Create a Model using the definition from above\n",
    "model = tf.keras.Model(inputs=[Input_layer], outputs=[Output_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "gR1LcamtbOWg",
    "outputId": "a76a15d9-42a2-4435-8bec-f16acd9993c1"
   },
   "outputs": [],
   "source": [
    "# Debug the model definition to check if everything looks good\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D00NKseRuOR3"
   },
   "outputs": [],
   "source": [
    "# Use a tf optimizer rather than a Keras one for now\n",
    "opt = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "model.compile(\n",
    "      optimizer=opt,\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mQnZM5JYlRvs"
   },
   "source": [
    "## Creating the TPU from a Keras Model\n",
    "\n",
    "tf.contrib.tpu.keras_to_tpu_model will eventually go away and you will pass it into the model.compile as a distribution strategy, but for 1.13.1 this works. \n",
    "\n",
    "We can see this is a TPUv2 with 8 cores  \n",
    "\n",
    "For batching you want to have a batch of 128 per core so 1024 overall  \n",
    "\n",
    "You could also use 128, 256, 512 etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "G-piuNdoWJGS",
    "outputId": "4a4656cd-cfc0-45b3-e049-655b83def0bb"
   },
   "outputs": [],
   "source": [
    "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
    "    model,\n",
    "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
    "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "g2u9PUA9W7NK",
    "outputId": "6ff090a6-12a9-4eff-baa8-3a9c76b24f37"
   },
   "outputs": [],
   "source": [
    "tpu_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_w2mss3nltod"
   },
   "source": [
    "## Training using tf.data pipeline \n",
    "\n",
    "Training (Fashion) MNIST on a TPU is a bit overkill and the TPU barely gets a chance to warm up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "colab_type": "code",
    "id": "x20Gu_lxXjOV",
    "outputId": "2385057d-e2be-4691-d80a-97a4c01c2e80"
   },
   "outputs": [],
   "source": [
    "tpu_model.fit(\n",
    "    train_input_fn,\n",
    "    steps_per_epoch = 60,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BbC4yE3zYFhL",
    "outputId": "dbfb283e-d1fe-4407-8f58-19df7b70de93"
   },
   "outputs": [],
   "source": [
    "tpu_model.save_weights('./Fash_MNIST_TPU_%d.h5' % batch_size, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "KOMRVG_YYloD",
    "outputId": "9bceeef9-9402-4ea6-ddf7-bb5a35382d31"
   },
   "outputs": [],
   "source": [
    "tpu_model.evaluate(test_input_fn,\n",
    "    steps = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hqMMMhPr4C0X"
   },
   "source": [
    "### Converting the model back to a CPU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xxljvuMZNppb",
    "outputId": "7d94649c-e47e-47cd-94bf-ce3b9c308064"
   },
   "outputs": [],
   "source": [
    "cpu_model = tpu_model.sync_to_cpu()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Guide to tf.keras TPU MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
